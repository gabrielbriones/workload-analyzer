# =============================================================================
# WORKLOAD ANALYZER ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and configure with your actual values
# DO NOT commit .env to version control - it contains sensitive credentials

# =============================================================================
# INTEL SIMULATION SERVICE (ISS) API CONFIGURATION
# =============================================================================

# ISS environment for dynamic URL construction (dev, test, prod)
ISS_ENVIRONMENT=test
# ISS API Base URL - Intel Simulation Service endpoint (note: paths start with /v1)
# Can be overridden with custom URL when targeting a custom API
# ISS_API_URL=https://custom-url.com

# Authentication domain for ISS token generation
AUTH_DOMAIN=https://azad.auth.us-west-2.amazoncognito.com/oauth2/token

# AWS Secrets Manager secret name containing ISS credentials
# Secret should contain: {"client_id": "...", "client_secret": "..."}
CLIENT_SECRET_NAME=test/cognito/client_creds/services-backend

# =============================================================================
# AWS CREDENTIALS FOR ISS AUTHENTICATION
# =============================================================================
# These may be different from Bedrock credentials if using separate accounts

# AWS credentials for accessing ISS secrets and authentication
AWS_ACCESS_KEY_ID_ISS=AKIA...
AWS_SECRET_ACCESS_KEY_ISS=...
AWS_REGION_ISS=us-west-2

# =============================================================================
# AWS BEDROCK AI INTEGRATION
# =============================================================================

# AWS credentials for Bedrock AI service (may be different account than ISS)
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=us-east-1

# =============================================================================
# BEDROCK AI MODEL CONFIGURATION
# =============================================================================

# Primary AI model for workload analysis
# Using Claude 4.5 Sonnet (latest available with inference profile support)
# Alternative: anthropic.claude-3-haiku-20240307-v1:0 for faster responses
BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0

# Model response parameters
BEDROCK_TEMPERATURE=0.7
BEDROCK_MAX_TOKENS=4096

# =============================================================================
# BEDROCK CHAT CONFIGURATION
# =============================================================================

# Custom system prompt for Intel workload analysis (optional)
BEDROCK_SYSTEM_PROMPT="You are an expert Intel simulation workload analyst. Help users optimize their IWPS, ISIM, and Coho simulation jobs. You have read-only access to Intel Simulation Service (ISS) APIs and file services. Job IDs are UUIDs (e.g., a2290337-a3d4-40db-904d-79222997688f). Focus on performance analysis, configuration guidance, and troubleshooting. Always explain your reasoning and cite specific data when available."

# API endpoint access control for ISS APIs (JSON array format)  
# Current read-only endpoints available to AI
BEDROCK_ALLOWED_PATHS=["/api/v1/jobs", "/api/v1/platforms", "/health"]

# Endpoints to exclude from AI access (security-sensitive and write operations)
BEDROCK_EXCLUDED_PATHS=["/bedrock-chat", "/docs", "/redoc", "/openapi.json"]

# Tool execution limits
BEDROCK_MAX_TOOL_CALLS=10
BEDROCK_TIMEOUT=180

# =============================================================================
# WEBSOCKET & SESSION CONFIGURATION
# =============================================================================

# Maximum concurrent chat sessions
BEDROCK_MAX_SESSIONS=1000

# Session timeout in seconds (1 hour default)
BEDROCK_SESSION_TIMEOUT=3600

# =============================================================================
# FASTAPI APPLICATION CONFIGURATION
# =============================================================================

# Application environment
APP_ENV=development

# API configuration
API_VERSION=v1
API_PREFIX=/api

# CORS settings for development (restrict in production)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8000
ALLOWED_METHODS=GET,POST,PUT,DELETE,OPTIONS
ALLOWED_HEADERS=*

# =============================================================================
# LOGGING & MONITORING
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable detailed request logging
REQUEST_LOGGING=true

# Metrics collection
ENABLE_METRICS=true

# =============================================================================
# DATABASE CONFIGURATION (if needed for local caching)
# =============================================================================

# Optional: Database for caching ISS responses and chat history
# DATABASE_URL=postgresql://user:pass@localhost:5432/workload_analyzer
# DATABASE_URL=sqlite:///./workload_analyzer.db

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT secret for session management (generate with: openssl rand -hex 32)
JWT_SECRET_KEY=your-secret-key-here

# API rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Enable HTTPS redirect in production
FORCE_HTTPS=false

# =============================================================================
# INTEL WORKLOAD SPECIFIC SETTINGS
# =============================================================================

# Default platform for new simulations
DEFAULT_PLATFORM=Intel-SPR-8380

# Default simulation timeout (hours)
DEFAULT_SIMULATION_TIMEOUT=24

# Cache simulation results (hours)
CACHE_RESULTS_TTL=168

# Maximum concurrent simulations per user
MAX_CONCURRENT_SIMULATIONS=5

# Tenant-specific resource limits
MAX_SIMULATIONS_PER_TENANT=100
TENANT_STORAGE_LIMIT_GB=1000

# File service configuration
FILE_DOWNLOAD_TIMEOUT=300
MAX_FILE_SIZE_MB=500
CACHE_FILES_LOCALLY=true

# =============================================================================
# DEVELOPMENT & DEBUGGING
# =============================================================================

# Enable debug mode (DO NOT use in production)
DEBUG=false

# Enable API documentation endpoints
ENABLE_DOCS=true

# Enable development tools
DEV_MODE=true

# Mock ISS API for testing (when ISS is unavailable)
MOCK_ISS_API=false

# =============================================================================
# EXAMPLE VALUES FOR DIFFERENT ENVIRONMENTS
# =============================================================================

# --- DEVELOPMENT ENVIRONMENT ---
# APP_ENV=development
# DEBUG=true
# LOG_LEVEL=DEBUG
# MOCK_ISS_API=true
# BEDROCK_MODEL_ID=anthropic.claude-3-haiku-20240307-v1:0  # Faster/cheaper

# --- STAGING ENVIRONMENT ---
# APP_ENV=staging
# DEBUG=false
# LOG_LEVEL=INFO
# BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0

# --- PRODUCTION ENVIRONMENT ---
# APP_ENV=production
# DEBUG=false
# LOG_LEVEL=WARNING
# FORCE_HTTPS=true
# RATE_LIMIT_PER_MINUTE=30
# BEDROCK_MODEL_ID=us.anthropic.claude-sonnet-4-5-20250929-v1:0  # Best quality

# =============================================================================
# NOTES
# =============================================================================
#
# 1. AWS Credentials Setup:
#    - For ISS: Ensure access to Secrets Manager and any ISS-specific services
#    - For Bedrock: Ensure model access is enabled in AWS Console
#
# 2. Model Access:
#    - Go to AWS Console → Amazon Bedrock → Model access
#    - Request access to desired models (Claude, Titan, Llama, etc.)
#    - Wait for approval (usually instant)
#    - Note: Some Claude models require inference profiles instead of direct access
#    - Use us.anthropic.claude-sonnet-4-5-20250929-v1:0 for best performance
#
# 3. Tenant Configuration:
#    - Tenant information comes from the job object returned by ISS API (job.TenantID field)
#    - Ensure your ISS credentials have access to the tenants in your jobs
#
# 4. ISS API Integration:
#    - ISS API endpoint: https://api-test.workloadmgr.intel.com (paths start with /v1)
#    - File service endpoint: https://gw-{tenant_id}-test.workloadmgr.intel.com where tenant_id comes from job TenantID field
#    - Job IDs are UUIDs (e.g., caef4de5-00e2-4483-b23c-b4bd3bbb5876)
#    - Use /fs/files/{job_id}/iwps/artifacts/out for simulation output files
#
# 5. Security:
#    - Use separate AWS accounts for ISS and Bedrock if required by your org
#    - Regularly rotate AWS credentials and JWT secrets
#    - Review BEDROCK_ALLOWED_PATHS and BEDROCK_EXCLUDED_PATHS regularly
#    - Use JSON array format for path lists: ["path1", "path2"]
#
# 6. Performance:
#    - Use Claude 3 Haiku for development (faster, cheaper)
#    - Use Claude 4.5 Sonnet for production (best quality with inference profile)
#    - Set BEDROCK_TIMEOUT to 180 seconds for large model responses
#
# 7. Monitoring:
#    - Enable REQUEST_LOGGING in development only
#    - Monitor BEDROCK_MAX_TOOL_CALLS to prevent API abuse
#    - Set appropriate BEDROCK_SESSION_TIMEOUT for your use case
#    - Monitor file download sizes and timeouts for performance
#